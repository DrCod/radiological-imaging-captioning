{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import pylab as pl\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import csv\n",
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "from keras.layers.noise import GaussianNoise\n",
    "import keras.models as models\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets\n",
    "DATASETS_PATH = \"./MontgomerySet/CXR_png/\"\n",
    "\n",
    "PREFIX = \"MCUCXR_\"\n",
    "SUFFIX = \"_0.png\"\n",
    "\n",
    "def get_image_filename(index):\n",
    "    num_zeros = 4-len(str(index))\n",
    "    img_path = PREFIX + \"0\"*num_zeros + str(index) + SUFFIX\n",
    "    return (DATASETS_PATH + img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./MontgomerySet/CXR_png/MCUCXR_0001_0.png'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_filename(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./MontgomerySet/CXR_png/MCUCXR_0011_0.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_image_filename(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH = \"./MontgomerySet/ClinicalReadings/\"\n",
    "\n",
    "label_list = os.listdir(LABELS_PATH)\n",
    "\n",
    "labels =[]\n",
    "for fname in label_list:\n",
    "    with open(os.path.join(LABELS_PATH,fname)) as f:\n",
    "            lines = f.read().splitlines(True)\n",
    "            caption =lines[-1]\n",
    "            labels.append(caption[:-1])\n",
    "    f.close()\n",
    "labels = np.asarray(labels)\n",
    "pd.DataFrame(labels).to_csv(\"./MontgomerySet/Labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0000_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0007_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0009_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0010_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0012_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0014_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0018_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0025_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0032_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0033_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0034_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0036_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0037_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0039_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0050_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0065_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0066_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0067_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0073_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0076_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0078_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0088_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0093_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0098_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0104_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0105_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0106_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0107_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0108_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0109_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0110_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0111_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0112_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0113_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0114_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0115_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0116_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0117_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0118_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0119_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0120_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0121_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0122_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0123_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0124_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0125_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0126_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0127_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0128_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0129_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0130_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0131_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0132_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0133_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0134_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0135_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0136_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0137_0.png\n",
      "No file found ./MontgomerySet/CXR_png/MCUCXR_0138_0.png\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"./MontgomerySet/\"\n",
    "\n",
    "reader = csv.reader(open(BASE_PATH + 'Labels.csv'))\n",
    "X =[]\n",
    "Y =[]\n",
    "\n",
    "for i,row in enumerate(reader):\n",
    "    if len(row) > 0:\n",
    "        filename = get_image_filename(i)\n",
    "        img_file = cv2.imread(filename)\n",
    "        if img_file is not None:\n",
    "            img_file = cv2.cvtColor(img_file, cv2.COLOR_BGR2RGB)\n",
    "            img_arr = np.asarray(img_file)\n",
    "            X.append(img_arr)\n",
    "            Y.append(row[1])\n",
    "        else:\n",
    "            print(\"No file found\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X)\n",
    "y =np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['extensive cavitary TB smear and culture positive involving LUL lungula and some areas in rt lung as well; pt had previously normal CXR (1Y ago) but positive TST and contact with active case',\n",
       "       'cavitary nodular infiltrate in RUL; active TB', 'normal',\n",
       "       'normal',\n",
       "       'rt pleural effusion with some nodular infiltrate in rt lower lung; there are findings also of previous cardiac surgery; suspicious for active TB.',\n",
       "       'normal',\n",
       "       'improved LUL infiltrate and cavity. Active TB on therapy.',\n",
       "       'peripheral homogeneous infiltrate LUL; active pneumonia likely',\n",
       "       'normal',\n",
       "       'bilateral miliary nodules diffusely with RML infiltrate and right pleural effusion; an old calcified granuloma is present behind heart in the LLL; all findings consistent with active TB',\n",
       "       '', 'normal', 'normal', 'normal',\n",
       "       'cavitary fibronodular infiltrate RUL. typical appearance of active TB.',\n",
       "       '',\n",
       "       'RUL fibrocavitary disease with volume loss and tracheal deviation to right; COPD scoliosis;',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'inactive scars RML. has completed treatment',\n",
       "       'RUL cavitary infiltrate; positive smear', 'normal',\n",
       "       'cavitary infiltrate near left hilum consistent with TB in superior segment LLL',\n",
       "       'improving infiltrate, active TB', 'normal',\n",
       "       'large right pleural effusion, positive TST, TB pleural effusion likely',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'active PTB with compicating CHF condition', 'normal', 'normal',\n",
       "       'normal', 'normal',\n",
       "       'persistent rt pleural peel with some interval improvement with focal atelectasis in rt lung; anterior wedging of T5, T6 with loss of intervertebral disc space. Findings consistent with h/o spinal TB and pleural TB. Currently on Rx.',\n",
       "       'normal',\n",
       "       'extensive infiltrates bilaterally with large cavity in RUL and a moderate pleural effusion on the left. AFB smears and RNA probes pos for MTB. Active TB, cavitary.',\n",
       "       'normal', 'normal', 'normal', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal',\n",
       "       'improvements after Rx. Has pleural, pulmonary, and probably percardial TB, pan-sensitive',\n",
       "       'inactive TB scars LUL, unchanged for 2Y, pt previously treated DOT (17Y ago) for pan-sensitive disease',\n",
       "       'normal', 'normal', '', 'normal', 'normal', 'normal',\n",
       "       'inactive and partly calcified scars and granulomas in RUL. pt completed 4HRZE 4HP DOT for neg culture smear (positive disease)',\n",
       "       'normal', 'normal', 'inactive TB scars', 'normal', 'normal',\n",
       "       'large infiltrate RUL with cavitation plus infiltrate in RML. consistent with active cavitary TB',\n",
       "       'normal',\n",
       "       'scoliosis to the left with some scarring in LLL and over the left apex; calcified granuloma in the rt lung. could be related to old TB.',\n",
       "       'bilateral calcified granulomas scars consistent with inactive TB.',\n",
       "       'improved infiltrates in both lungs; a cavity is now visible in lingula compared with 1M ago. culture positive, pan-sensitive, on HRZ(E) since 1M',\n",
       "       'normal', 'pleural TB, on treatment', 'normal',\n",
       "       'inactive scars RUL', 'normal',\n",
       "       'RUL infiltrate consistent with TB', 'normal', 'normal', 'normal',\n",
       "       'normal', 'normal'], dtype='<U231')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#caption vectorization\n",
    "token_index ={}\n",
    "\n",
    "for sample in y:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "max_length = 100\n",
    "results = np.zeros(shape=(len(y),max_length, max(token_index.values())+ 1))\n",
    "\n",
    "for i, sample in enumerate(y):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i,j,index] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
